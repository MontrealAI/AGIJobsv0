"""Command-line entrypoint for the Meta-Agentic Program Synthesis demo."""

from __future__ import annotations

import argparse
import json
import math
from datetime import UTC, datetime, timedelta
from pathlib import Path
from textwrap import indent
from typing import Mapping

from meta_agentic_demo.admin import OwnerConsole, load_owner_overrides
from meta_agentic_demo.config import DatasetProfile, DemoConfig, DemoScenario
from meta_agentic_demo.dashboard import export_dashboard
from meta_agentic_demo.entities import DemoRunArtifacts
from meta_agentic_demo.governance import GovernanceTimelock
from meta_agentic_demo.orchestrator import SovereignArchitect
from meta_agentic_demo.report import ReportBundle, export_report
from meta_agentic_demo.scenarios import (
    ScenarioValidationError,
    resolve_scenarios,
    serialise_scenarios,
)


ALL_SCENARIOS_IDENTIFIER = "all"

DEFAULT_SCENARIOS = [
    DemoScenario(
        identifier="alpha",
        title="Alpha Efficiency Sweep",
        description=(
            "Ask the sovereign architect to refine an internal automation workflow, "
            "discovering an increasingly efficient control signal."
        ),
        target_metric="Workflow productivity uplift",
        success_threshold=0.82,
        dataset_profile=DatasetProfile(length=64, noise=0.05, seed=1_337),
    ),
    DemoScenario(
        identifier="atlas",
        title="Atlas Market Sentinel",
        description=(
            "Hunt for cross-market inefficiencies by evolving a forecasting kernel that "
            "beats the benchmark risk-adjusted score."
        ),
        target_metric="Information ratio",
        success_threshold=0.78,
        dataset_profile=DatasetProfile(length=72, noise=0.06, seed=4_242),
        stress_multiplier=1.1,
    ),
    DemoScenario(
        identifier="sovereign",
        title="Sovereign Hyperdrive Forge",
        description=(
            "Let the sovereign architect synthesise breakthrough control kernels across "
            "markets, operations, and intelligence â€” compressing cycles to minutes."
        ),
        target_metric="Hyperdrive innovation index",
        success_threshold=0.85,
        dataset_profile=DatasetProfile(length=96, noise=0.07, seed=90_900),
        stress_multiplier=1.35,
    ),
    DemoScenario(
        identifier="imperium",
        title="Imperium Continuum Grid",
        description=(
            "Launch a cross-domain command lattice that unifies liquidity, logistics, "
            "and intelligence theatres into a continuously self-rewriting engine."
        ),
        target_metric="Continuum dominance quotient",
        success_threshold=0.9,
        dataset_profile=DatasetProfile(length=112, noise=0.085, seed=808_808),
        stress_multiplier=1.55,
    ),
]


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument(
        "scenario",
        nargs="?",
        default=ALL_SCENARIOS_IDENTIFIER,
        help="Identifier of the narrative to execute or 'all' for the full constellation",
    )
    parser.add_argument(
        "--output",
        type=Path,
        default=Path("demo_output"),
        help="Directory where artefacts should be written",
    )
    parser.add_argument(
        "--config-file",
        type=Path,
        help="Optional JSON file containing owner overrides",
    )
    parser.add_argument(
        "--scenario-file",
        type=Path,
        action="append",
        help="Path to a JSON file defining scenario overrides",
    )
    parser.add_argument(
        "--scenario-json",
        action="append",
        help="Inline JSON payload describing scenario overrides",
    )
    parser.add_argument(
        "--list-scenarios",
        action="store_true",
        help="List the configured scenarios after applying overrides and exit",
    )

    owner_group = parser.add_argument_group("Owner overrides")
    owner_group.add_argument("--reward-total", type=float, help="Override total reward size")
    owner_group.add_argument(
        "--reward-temperature",
        type=float,
        help="Override thermodynamic temperature",
    )
    owner_group.add_argument(
        "--reward-validator-weight",
        type=float,
        help="Portion of rewards dedicated to validators",
    )
    owner_group.add_argument(
        "--reward-architect-weight",
        type=float,
        help="Portion of rewards retained by the architect",
    )
    owner_group.add_argument(
        "--stake-minimum",
        type=float,
        help="Override minimum stake per agent",
    )
    owner_group.add_argument(
        "--stake-slash-fraction",
        type=float,
        help="Override slashing fraction",
    )
    owner_group.add_argument(
        "--stake-timeout",
        type=float,
        help="Override inactivity timeout in seconds",
    )
    owner_group.add_argument(
        "--evolution-generations",
        type=int,
        help="Override number of generations",
    )
    owner_group.add_argument(
        "--evolution-population",
        type=int,
        help="Override population size",
    )
    owner_group.add_argument(
        "--evolution-elite",
        type=int,
        help="Override elite count",
    )
    owner_group.add_argument(
        "--evolution-mutation",
        type=float,
        help="Override mutation rate",
    )
    owner_group.add_argument(
        "--evolution-crossover",
        type=float,
        help="Override crossover rate",
    )
    owner_group.add_argument(
        "--pause",
        action="store_true",
        help="Pause operations before they begin (no jobs executed)",
    )
    verification_group = parser.add_argument_group("Verification policy")
    verification_group.add_argument(
        "--verification-holdout-threshold",
        type=float,
        help="Override minimum acceptable holdout score",
    )
    verification_group.add_argument(
        "--verification-residual-mean",
        type=float,
        help="Override residual mean tolerance",
    )
    verification_group.add_argument(
        "--verification-residual-std",
        type=float,
        help="Override residual standard deviation minimum",
    )
    verification_group.add_argument(
        "--verification-divergence",
        type=float,
        help="Override maximum allowed holdout divergence",
    )
    verification_group.add_argument(
        "--verification-mae-threshold",
        type=float,
        help="Override acceptable MAE-derived score threshold",
    )
    verification_group.add_argument(
        "--verification-monotonic",
        type=float,
        help="Override tolerance for monotonic improvement checks",
    )
    verification_group.add_argument(
        "--verification-bootstrap",
        type=int,
        help="Override bootstrap iteration count",
    )
    verification_group.add_argument(
        "--verification-confidence",
        type=float,
        help="Override bootstrap confidence level (0-1)",
    )
    verification_group.add_argument(
        "--verification-stress-threshold",
        type=float,
        help="Override minimum acceptable stress test score",
    )
    verification_group.add_argument(
        "--verification-entropy",
        type=float,
        help="Override minimum acceptable entropy score",
    )
    verification_group.add_argument(
        "--verification-precision-tolerance",
        type=float,
        help="Override tolerance for decimal replay consistency",
    )
    verification_group.add_argument(
        "--verification-variance-ceiling",
        type=float,
        help="Override maximum acceptable variance ratio",
    )
    verification_group.add_argument(
        "--verification-spectral-ceiling",
        type=float,
        help="Override maximum acceptable spectral energy ratio",
    )
    governance_group = parser.add_argument_group("Governance timelock")
    governance_group.add_argument(
        "--timelock-delay",
        type=float,
        default=0.0,
        help="Seconds to delay owner overrides via the governance timelock",
    )
    governance_group.add_argument(
        "--timelock-fast-forward",
        type=float,
        default=0.0,
        help="Advance the timelock clock by N seconds before execution",
    )
    return parser.parse_args()


def normalise_scenario_payload(data: object) -> dict[str, object]:
    """Normalise user-provided scenario payloads into a standard mapping."""

    if isinstance(data, Mapping):
        payload = dict(data)
        if "definitions" in payload and "scenarios" not in payload:
            payload["scenarios"] = payload.pop("definitions")
        if "scenarios" not in payload:
            return {"mode": "merge", "scenarios": data}
        mode = str(payload.get("mode", "merge"))
        return {"mode": mode, "scenarios": payload["scenarios"]}
    return {"mode": "merge", "scenarios": data}


def describe_config(config: DemoConfig) -> str:
    summary = config.as_summary()
    return json.dumps(summary, indent=2)


def main() -> None:
    args = parse_args()
    owner_console = OwnerConsole(DemoConfig(scenarios=list(DEFAULT_SCENARIOS)))
    timelock = GovernanceTimelock(
        default_delay=timedelta(seconds=max(args.timelock_delay, 0.0))
    )
    scheduled_actions: list = []
    scenario_payload_queue: list[dict[str, object]] = []

    def queue_timelock(action: str, payload: Mapping[str, object]) -> bool:
        try:
            scheduled_actions.append(timelock.schedule(action, payload))
            return True
        except (ValueError, KeyError) as error:
            print("âŒ Owner override error:", error)
            return False

    def enqueue_scenario_payload(data: object, *, source: str) -> bool:
        try:
            scenario_payload_queue.append(normalise_scenario_payload(data))
            return True
        except Exception as error:  # pragma: no cover - defensive path
            print(f"âŒ Scenario override error ({source}):", error)
            return False

    try:
        if args.config_file:
            overrides = load_owner_overrides(args.config_file)
            scenario_override = overrides.pop("scenarios", None)
            if scenario_override is not None and not enqueue_scenario_payload(
                scenario_override, source=str(args.config_file)
            ):
                return
            reward_overrides = overrides.get("reward_policy", {})
            if reward_overrides and not queue_timelock(
                "update_reward_policy", reward_overrides
            ):
                return
            stake_overrides = overrides.get("stake_policy", {})
            if stake_overrides and not queue_timelock("update_stake_policy", stake_overrides):
                return
            evolution_overrides = overrides.get("evolution_policy", {})
            if evolution_overrides and not queue_timelock(
                "update_evolution_policy", evolution_overrides
            ):
                return
            verification_overrides = overrides.get("verification_policy", {})
            if verification_overrides and not queue_timelock(
                "update_verification_policy", verification_overrides
            ):
                return
            if "paused" in overrides and not queue_timelock(
                "set_paused", {"value": bool(overrides["paused"]) }
            ):
                return
        reward_overrides = {
            key: value
            for key, value in {
                "total_reward": args.reward_total,
                "temperature": args.reward_temperature,
                "validator_weight": args.reward_validator_weight,
                "architect_weight": args.reward_architect_weight,
            }.items()
            if value is not None
        }
        if reward_overrides and not queue_timelock("update_reward_policy", reward_overrides):
            return
        stake_overrides = {
            key: value
            for key, value in {
                "minimum_stake": args.stake_minimum,
                "slash_fraction": args.stake_slash_fraction,
                "inactivity_timeout_seconds": args.stake_timeout,
            }.items()
            if value is not None
        }
        if stake_overrides and not queue_timelock("update_stake_policy", stake_overrides):
            return
        evolution_overrides = {
            key: value
            for key, value in {
                "generations": args.evolution_generations,
                "population_size": args.evolution_population,
                "elite_count": args.evolution_elite,
                "mutation_rate": args.evolution_mutation,
                "crossover_rate": args.evolution_crossover,
            }.items()
            if value is not None
        }
        if evolution_overrides and not queue_timelock(
            "update_evolution_policy", evolution_overrides
        ):
            return
        verification_overrides = {
            key: value
            for key, value in {
                "holdout_threshold": args.verification_holdout_threshold,
                "residual_mean_tolerance": args.verification_residual_mean,
                "residual_std_minimum": args.verification_residual_std,
                "divergence_tolerance": args.verification_divergence,
                "mae_threshold": args.verification_mae_threshold,
                "monotonic_tolerance": args.verification_monotonic,
                "bootstrap_iterations": args.verification_bootstrap,
                "confidence_level": args.verification_confidence,
                "stress_threshold": args.verification_stress_threshold,
                "entropy_floor": args.verification_entropy,
                "precision_replay_tolerance": args.verification_precision_tolerance,
                "variance_ratio_ceiling": args.verification_variance_ceiling,
                "spectral_energy_ceiling": args.verification_spectral_ceiling,
            }.items()
            if value is not None
        }
        if verification_overrides and not queue_timelock(
            "update_verification_policy", verification_overrides
        ):
            return
        if args.pause and not queue_timelock("set_paused", {"value": True}):
            return
        if args.scenario_file:
            for path in args.scenario_file:
                try:
                    payload_data = json.loads(path.read_text(encoding="utf-8"))
                except OSError as error:
                    print(f"âŒ Unable to read scenario file {path}:", error)
                    return
                except json.JSONDecodeError as error:
                    print(f"âŒ Scenario file {path} is not valid JSON:", error)
                    return
                if not enqueue_scenario_payload(payload_data, source=str(path)):
                    return
        if args.scenario_json:
            for index, raw in enumerate(args.scenario_json, start=1):
                try:
                    payload_data = json.loads(raw)
                except json.JSONDecodeError as error:
                    print(f"âŒ Scenario JSON override #{index} is invalid:", error)
                    return
                if not enqueue_scenario_payload(payload_data, source=f"cli:{index}"):
                    return
    except ValueError as error:
        print("âŒ Owner override error:", error)
        return

    if scenario_payload_queue:
        effective_scenarios = list(owner_console.config.scenarios)
        try:
            for payload in scenario_payload_queue:
                effective_scenarios = resolve_scenarios(
                    effective_scenarios,
                    payload["scenarios"],
                    mode=payload.get("mode", "merge"),
                )
        except ScenarioValidationError as error:
            print("âŒ Scenario override error:", error)
            return
        final_payload = {
            "mode": "replace",
            "scenarios": serialise_scenarios(effective_scenarios),
        }
        if not queue_timelock("set_scenarios", final_payload):
            return

    fast_forward_seconds = max(args.timelock_fast_forward, 0.0)
    execution_time = datetime.now(UTC) + timedelta(seconds=fast_forward_seconds)
    try:
        executed_actions = tuple(timelock.execute_due(owner_console, now=execution_time))
    except ValueError as error:
        print("âŒ Timelock execution error:", error)
        return

    if scheduled_actions:
        print("\nğŸ›¡ï¸ Governance timelock queue:")
        for action in timelock.pending():
            eta = action.eta.isoformat(timespec="seconds")
            status = action.status
            if action.executed_at:
                status = f"{status} at {action.executed_at.isoformat(timespec='seconds')}"
            print(
                f"  â€¢ {action.name} -> {dict(action.payload)} (ETA {eta}) :: {status}"
            )
        if fast_forward_seconds > 0:
            print(
                f"  â€¢ Timelock fast-forward applied: +{fast_forward_seconds:.1f} seconds"
            )
        if executed_actions:
            print(f"  â€¢ Executed {len(executed_actions)} action(s) ready for execution")

    config = owner_console.config
    scenario_lookup = {scenario.identifier: scenario for scenario in config.scenarios}
    if not scenario_lookup:
        print("âŒ Scenario catalogue is empty after applying overrides.")
        return
    if args.list_scenarios:
        print("\nğŸ“‹ Scenario catalogue:")
        for scenario in config.scenarios:
            if scenario.dataset_profile:
                profile = scenario.dataset_profile
                dataset_summary = (
                    f"length={profile.length}, noise={profile.noise:.3f}, seed={profile.seed}"
                )
            else:
                dataset_summary = "default dataset"
            print(
                "  â€¢",
                f"{scenario.identifier}: {scenario.title}",
                f"(threshold={scenario.success_threshold:.2f},",
                f"stress={scenario.stress_multiplier:.2f}Ã—,",
                f"{dataset_summary})",
            )
        return
    if args.scenario == ALL_SCENARIOS_IDENTIFIER:
        selected_scenarios = list(config.scenarios)
    else:
        if args.scenario not in scenario_lookup:
            print(f"âŒ Unknown scenario identifier: {args.scenario}")
            print("   Available:", ", ".join(sorted(scenario_lookup)))
            return
        selected_scenarios = [scenario_lookup[args.scenario]]
    multi_run = len(selected_scenarios) > 1
    aggregated_results: dict[str, DemoRunArtifacts] = {}
    bundles: dict[str, ReportBundle] = {}
    batch_bundle: ReportBundle | None = None

    for index, scenario in enumerate(selected_scenarios, start=1):
        architect = SovereignArchitect(
            config=config,
            owner_console=owner_console,
            timelock=timelock,
        )
        header = f"Scenario {index}/{len(selected_scenarios)}" if multi_run else "Scenario"
        print(f"\nğŸš€ {header}: {scenario.title}")
        print(indent(scenario.description, prefix="  > "))
        print("\nğŸ§­ Configuration:")
        print(indent(describe_config(config), prefix="  "))
        if scenario.dataset_profile:
            profile = scenario.dataset_profile
            print(
                "\nğŸ§ª Scenario dataset profile:",
                f"length={profile.length}, noise={profile.noise:.3f}, seed={profile.seed}",
            )
        if not math.isclose(scenario.stress_multiplier, 1.0):
            print(
                f"\nğŸŒ¡ï¸ Stress profile amplified: {scenario.stress_multiplier:.2f}Ã— thermodynamic stress battery",
            )
        if owner_console.is_paused:
            print("\nâ¸ï¸ Operations paused by owner. Resume to execute jobs.")
            return
        artefacts = architect.run(scenario)
        output_dir = args.output / scenario.identifier if multi_run else args.output
        bundle = export_report(artefacts, output_dir)
        aggregated_results[scenario.identifier] = artefacts
        bundles[scenario.identifier] = bundle
        print("\nâœ… Demo complete. Artefacts written to:")
        print(f"  â€¢ JSON: {bundle.json_path}")
        print(f"  â€¢ HTML: {bundle.html_path}")
        print("\nğŸ Final program:")
        print(indent(artefacts.final_program, prefix="  "))
        print(f"Composite score: {artefacts.final_score:.4f}")
        print(f"Improvement vs first generation: {artefacts.improvement_over_first:.4f}")
        print(f"Stress multiplier applied: {architect.stress_multiplier:.2f}Ã—")
        if artefacts.first_success_generation is not None:
            print(
                "Success threshold achieved at generation",
                artefacts.first_success_generation,
            )
        else:
            print("Success threshold not reached within configured generations.")
        summary = artefacts.reward_summary
        print("\nğŸ’  Reward distribution overview:")
        print(f"  â€¢ Total disbursed: {summary.total_reward:.2f} $AGIÎ±")
        print(f"  â€¢ Architect retained: {summary.architect_total:.2f} $AGIÎ±")
        if summary.top_solver:
            print(
                f"  â€¢ Top solver: {summary.top_solver} -> {summary.solver_totals[summary.top_solver]:.2f} $AGIÎ±"
            )
        if summary.top_validator:
            print(
                "  â€¢ Top validator:",
                summary.top_validator,
                "->",
                f"{summary.validator_totals[summary.top_validator]:.2f} $AGIÎ±",
            )
        print("\nğŸ§µ Triple-verification digest:")
        digest = artefacts.verification
        print(
            f"  â€¢ Holdout pass: {digest.pass_holdout} (scores={json.dumps(digest.holdout_scores)})"
        )
        print(
            f"  â€¢ Residual balance: mean={digest.residual_mean:.4f}, std={digest.residual_std:.4f}, pass={digest.pass_residual_balance}"
        )
        print(
            f"  â€¢ Divergence tolerance: {digest.divergence:.4f} (pass={digest.pass_divergence})"
        )
        print(
            f"  â€¢ MAE shield: score={digest.mae_score:.4f} (pass={digest.pass_mae})"
        )
        print(
            f"  â€¢ Bootstrap confidence: {digest.bootstrap_interval[0]:.4f}-{digest.bootstrap_interval[1]:.4f}"
            f" @ {digest.pass_confidence}"
        )
        print(
            f"  â€¢ Stress battery: {json.dumps(digest.stress_scores)} (threshold={digest.stress_threshold:.2f}, pass={digest.pass_stress})"
        )
        print(
            f"  â€¢ Resilience index: {digest.resilience_index:.4f} (harmonised stress/entropy/confidence)"
        )
        print(
            f"  â€¢ Entropy shield: score={digest.entropy_score:.4f} (floor={digest.entropy_floor:.2f}, pass={digest.pass_entropy})"
        )
        print(
            f"  â€¢ Precision replay: score={digest.precision_replay_score:.4f}"
            f" (tolerance={owner_console.config.verification_policy.precision_replay_tolerance:.4f}, pass={digest.pass_precision_replay})"
        )
        print(
            f"  â€¢ Variance ratio: {digest.variance_ratio:.4f} (ceiling={owner_console.config.verification_policy.variance_ratio_ceiling:.2f}, pass={digest.pass_variance_ratio})"
        )
        print(
            f"  â€¢ Spectral leak: {digest.spectral_ratio:.4f} (ceiling={owner_console.config.verification_policy.spectral_energy_ceiling:.2f}, pass={digest.pass_spectral_ratio})"
        )
        print("  â€¢ Overall verdict:", "PASS" if digest.overall_pass else "ATTENTION")

        if artefacts.opportunities:
            print("\nğŸ“ˆ Opportunity intelligence cues:")
            for opportunity in artefacts.opportunities:
                print(
                    f"  â€¢ {opportunity.name}: impact={opportunity.impact_score:.2f},"
                    f" confidence={opportunity.confidence:.2f} :: {opportunity.narrative}"
                )
        else:
            print("\nğŸ“ˆ No opportunities surfaced during this run.")

        if artefacts.timelock_actions:
            print("\nâ±ï¸ Governance timelock ledger:")
            for action in artefacts.timelock_actions:
                print(
                    f"  â€¢ {action.name} (status={action.status}, ETA={action.eta.isoformat(timespec='seconds')})"
                )
        else:
            print("\nâ±ï¸ Governance timelock ledger is empty â€“ sovereign operated in real-time.")

        if artefacts.owner_actions:
            print("\nğŸ›¡ï¸ Owner interventions recorded:")
            for action in artefacts.owner_actions:
                print(
                    f"  â€¢ {action.timestamp.isoformat(timespec='seconds')} :: {action.action} -> {json.dumps(action.payload)}"
                )
        else:
            print("\nğŸ›¡ï¸ Owner interventions not required â€“ configuration remained stable.")

    if multi_run:
        from meta_agentic_demo.report import export_batch_report

        batch_bundle = export_batch_report(
            aggregated_results,
            args.output,
            bundles,
            scenarios={scenario.identifier: scenario for scenario in selected_scenarios},
        )
        print("\nğŸŒŒ Mission constellation synthesised:")
        print(f"  â€¢ JSON: {batch_bundle.json_path}")
        print(f"  â€¢ HTML: {batch_bundle.html_path}")

    dashboard_bundle = export_dashboard(
        aggregated_results,
        output_dir=args.output,
        bundles=bundles,
        scenarios={scenario.identifier: scenario for scenario in selected_scenarios},
        batch_bundle=batch_bundle,
    )
    print("\nğŸ›°ï¸ Command theatre assembled:")
    print(f"  â€¢ Dashboard: {dashboard_bundle.html_path}")
    print(f"  â€¢ Data: {dashboard_bundle.json_path}")


if __name__ == "__main__":
    main()
